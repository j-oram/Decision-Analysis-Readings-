---
title: 'Chapter 4: Bayesian Analysis'
author: "Jacob Oram"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

This is a massive chapter, because it covers the entire Bayesian paradigm. Perhaps because this book was written in 1985, the first section of this chapter begins with seven detailed arguments in favor of using Bayesian analysis (perhaps useful for a future Stat 532 course debate). The second section introduces the concept of a posterior distribution. The third section is about Bayesian inference. I focused my reading on section four, which is concerned with Bayesian decision theory. 

## Definitions 

<hr>

__Definition 8a__: The *posterior expected loss* of an action $a$, is 

\[
\rho(\pi(\theta|x), a) = \int_\Theta L(\theta, a) \pi(\theta|x)d\theta,
\]

where $\pi(\theta|x)$ is the posterior distribution on $\theta.$ 


Essentially, we are averaging the loss of $a$ over all the possible states of nature $\theta.$ With this updated definition (see Chapter 1), we can also define the *posterior Bayes action* 

__Definition 8b__: The *posterior Bayes action*, $\delta^\pi(x)$ is any action $a \in \mathscr{A}$ which minimizes the posterior expected loss, $\rho(\pi(\theta|x),a).$ 
<hr>



<hr>
__Definition 6__: (Chapter 1) The *Bayes risk* of a decision rule $\delta,$ with respect to posterior distribution $\pi$ on $\Theta$ is defined as 
\[
r(\pi, \delta) = E^\pi[R(\theta, \delta)].
\]

The decision rule $\delta^\pi$ which minimizes $r(\pi, \delta)$ is called a *Bayes Rule* and the quantity $r(\pi) = r(\pi, \delta^\pi)$ is called the *Bayes risk* for $\pi$.



Note to self: the Bayes risk is obtained by first averaging the loss over the data X (to obtain the risk), then averaging the risk over the distribution for $\theta:$ 

\[
r(\pi, \delta) = \int_\Theta R(\theta, \delta)\pi(\theta)d\theta \\
= \int_\Theta \left[ \int_\mathscr{X} L(\theta, \delta(x)) f(x|\theta)dx \right] \pi(\theta) d\theta
\]

<hr>
__Definition 9__: If $\pi$ is an improper prior, but $\delta^\pi(x)$ is an action which minimizes the expected posteriior loss $\rho(\pi(\theta|x), \delta(x))$ for each $x$ with $m(x)>0$, then $\delta^\pi$ is called a *generalized Bayes rule*. 
<hr>

__Definition 10__: The *$\Gamma$-posterior expected loss of $a_0$* is 

\[
\rho_\Gamma(a_0) = \sup_{\pi \in \Gamma} \rho(\pi(\theta|x), a_0),
\]

where $\Gamma$ is a class of possible prior distributions on $\theta$. 
<hr>

__Definition 11__: An action $a_0$ is said to be *$\epsilon$-posterior robust* with respect to prior class $\Gamma$ if , for all $\pi \in \Gamma$, 
\[
\left| \rho(\pi(\theta|x), a_0) - \inf_a \rho(\pi(\theta|x), a)\right| \leq \epsilon 
\]

## Key Results 

__Result 2__
If $\delta$ is a nonrandomized estimator, then 
\[ r(\pi, \delta) = \int_{\{x:m(x)>0\}} \rho(\pi(\theta|x),\delta(x))m(x)dx\]

__Result 1__
A Bayes rule $\delta^\pi$ (i.e., a rule minimizing $r(\pi, \delta))$ can be found by choosing, for each $x$ such that $m(x) > 0$, an action which minimizes the posterior expected loss. The rule can be defined arbitrarily when $m(x) = 0$.

The results are listed out of order because 1 follows from 2. Together they imply that minimizing the (frequentist) Bayes risk $r(\pi, \delta)$ is essentially the same problem as minimizing the expected posterior loss. 

## Section 4.4: Bayesian Decision Theory 


After taking the reader through the above results and definitions, Berger outlines the Bayes rules for estimation with several standard loss functions. 
In estimation, the Bayes rule is the estimator denoted as $a$ or $\delta^\pi$ that minimizes posterior expected loss. 
I did not write up the results here because they would are examples more than key theoretical results. 

The next subsubsection involves finite action problems; these include hypothesis testing and (more interestingly for modern problems) classification. 
The use of decision analysis in classification is illustrated with an example (p.166). 

## Section 4.5: Empirical Bayes 

Briefly, empirical Bayes problems are ones where known relationships between the parameter values allow the use of the data to inform the prior distribution. 
An example is in a multi-level model, where parameters $\theta_i$ arise from a common population with its own distribution controlled by hyperparameters. 
The trick is that the population model is then interpreted as the prior. 

An example is given in subsection 4.5.2, which focuses on parametric methods for empirical Bayes: 

Suppose that $X_i$ are realized test scores of students. The assumed likelihood for these data is

\[
X_i \sim N(\theta_i, \sigma^2_f) \\
\theta_i \sim N(\mu_\pi, \sigma^2_\pi),
\]

where $\theta_i$ is assumed to be the true ability level of individual $i$ and $\sigma_f^2$ is (known) reliability of test scores. 
We assume that these true ability levels are normally distributed in the population, with mean $\mu_pi$ and variance $\sigma^2_\pi$ (both of which are unknown). 
The empirical Bayes approach is concerned with estimating $\mu_\pi$ and $\sigma^2_\pi$ from the data using the marginal distribution $m(x)$. 
This follows somewhat closely with the hierarchical model laid out in Gelman et al., (2013), section 5.4 and the eight schools example in section 5.5. 

## 4.6 Hierarchical Bayes 

I skipped this section because I prefer the treatment in Gelman et al., (2013). 

## 4.7 Bayesian Robustness 

This section addresses robustness of Bayesian analysis to prior specification. 
There is a very short discussion of robustness of decision analysis to the choice of loss function at the very end of the section, but the author argues that the choice of prior is far more challenging with greater implications for resulting decisions. 

More interesting is how posterior robustness is framed in terms of actions $a$. 
There seems to be an implicit assumption that the action $a$ is a choice of estimate for the parameter of interest, but I see no reason why we would not be able to extend this to possible actions after inference has been made. 
The idea of posterior expected loss for a class of priors (as given in Definition 10 above) can be extended to consider a range of values for the posterior expected losses for action $a_0$:

\[
\left(
\inf_{\pi \in \Gamma} \rho(\pi(\theta|x), a_0), \sup_{\pi \in \Gamma} \rho(\pi(\theta|x), a_0)
\right).
\]


## 4.8 Admissability of Bayes Rules 

Generally, a Bayes rule is always admissible (i.e., there does not exist a different rule $\delta$ with lower risk for all $\theta \in \Theta$), because if there was, that alternative rule would also have lower Bayes risk $r(\pi, \delta).$ The following three theorems are proven by contradiction using this line of reasoning. 

__Theorem 7 (9)__: Assume that $\Theta$ is discrete (say $\Theta = \{\theta_1, \theta_2, \dots\}$) and that the prior $\pi$ gives positive mass to each $\theta_i \in \Theta$. A Bayes rule $\delta^\pi$ is then admissible with respect to $\pi$. 

The statement for theorem 9 is essentially the same, but for a continuous parameter space. In this case, the theorem assumes that the risk function is continuous and that the prior gives positive probability to any open subset of $\Theta.$ 

__Theorem 8__: If a Bayes rule is unique, then it is admissible. 


Berger also discusses generalized Bayes rules, which are Bayes rules from an improper prior. 
He mentions that although it's less clear what we mean exactly by $r(\pi, \delta)$ if the prior is improper, the Bayes rule minimizing $r(\pi, \delta)$ is still found by minimizing posterior expected loss. 
When the expected risk, averaging over prior uncertainty in $\theta$ is not finite (that is, when $r(\pi, \delta) = \infty$, which is not uncommon when the prior is improper), even natural Bayes rules (such as the posterior mean in estimation problems) may not be admissible.  






