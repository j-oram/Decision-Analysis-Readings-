---
title: 'Chapter 4: Bayesian Analysis'
author: "Jacob Oram"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

This is a massive chapter, because it covers the entire Bayesian paradigm. Perhaps because this book was written in 1985, the first section of this chapter begins with seven detailed arguments in favor of using Bayesian analysis (perhaps useful for a future Stat 532 course debate). The second section introduces the concept of a posterior distribution. The third section is about Bayesian inference. I focused my reading on section four, which is concerned with Bayesian decision theory. 

## Definitions 

<hr>

__Definition 8a__: The *posterior expected loss* of an action $a$, is 

\[
\rho(\pi(\theta|x), a) = \int_\Theta L(\theta, a) \pi(\theta|x)d\theta,
\]

where $\pi(\theta|x)$ is the posterior distribution on $\theta.$ 


Essentially, we are averaging the loss of $a$ over all the possible states of nature $\theta.$ With this updated definition (see Chapter 1), we can also define the *posterior Bayes action* 

__Definition 8b__: The *posterior Bayes action*, $\delta^\pi(x)$ is any action $a \in \mathscr{A}$ which minimizes the posterior expected loss, $\rho(\pi(\theta|x),a).$ 
<hr>



<hr>
__Definition 6__: (Chapter 1) The *Bayes risk* of a decision rule $\delta,$ with respect to posterior distribution $\pi$ on $\Theta$ is defined as 
\[
r(\pi, \delta) = E^\pi[R(\theta, \delta)].
\]

The decision rule $\delta^\pi$ which minimizes $r(\pi, \delta)$ is called a *Bayes Rule* and the quantity $r(\pi) = r(\pi, \delta^\pi)$ is called the *Bayes risk* for $\pi$.



Note to self: the Bayes risk is obtained by first averaging the loss over the data X (to obtain the risk), then averaging the risk over the distribution for $\theta:$ 

\[
r(\pi, \delta) = \int_\Theta R(\theta, \delta)\pi(\theta)d\theta \\
= \int_\Theta \left[ \int_\mathscr{X} L(\theta, \delta(x)) f(x|\theta)dx \right] d\theta
\]

<hr>
__Definition 9__: If $\pi$ is an improper prior, but $\delta^\pi(x)$ is an action which minimizes the expected posteriior loss $\rho(\pi(\theta|x), \delta(x))$ for each $x$ with $m(x)>0$, then $\delta^\pi$ is called a *generalized Bayes rule*. 
<hr>

## Key Results 

__Result 2__
If $\delta$ is a nonrandomized estimator, then 
\[ r(\pi, \delta) = \int_{\{x:m(x)>0\}} \rho(\pi(\theta|x),\delta(x))m(x)dx\]

__Result 1__
A Bayes rule $\delta^\pi$ (i.e., a rule minimizing $r(\pi, \delta))$ can be found by choosing, for each $x$ such that $m(x) > 0$, an action which minimizes the posterior expected loss. The rule can be defined arbitrarily when $m(x) = 0$.

The results are listed out of order because 1 follows from 2. Together they imply that minimizing the (frequentist) Bayes risk $r(\pi, \delta)$ is essentially the same problem as minimizing the expected posterior loss. 

## Section 4.4: Bayesian Decision Theory 


After taking the reader through the above results and definitions, Berger outlines the Bayes rules for estimation with several standard loss functions. 
In estimation, the Bayes rule is the estimator denoted as $a$ or $\delta^\pi$ that minimizes posterior expected loss. 
I did not write up the results here because they would are examples more than key theoretical results. 

The next subsubsection involves finite action problems; these include hypothesis testing and (more interestingly for modern problems) classification. 
The use of decision analysis in classification is illustrated with an example (p.166). 

## Section 4.5: Empirical Bayes 

Briefly, empirical Bayes problems are ones where known relationships between the parameter values allow the use of the data to inform the prior distribution. 
An example is in a multi-level model, where parameters $\theta_i$ arise from a common population with its own distribution controlled by hyperparameters. 
The trick is that the population model is then interpreted as the prior. 

An example is given in subsection 4.5.2, which focuses on parametric methods for empirical Bayes: 

Suppose that $X_i$ are realized test scores of students. The assumed likelihood for these data is

\[
X_i \sim N(\theta_i, \sigma^2_f) \\
\theta_i \sim N(\mu_\pi, \sigma^2_\pi),
\]

where $\theta_i$ is assumed to be the true ability level of individual $i$ and $\sigma_f^2$ is (known) reliability of test scores. 
We assume that these true ability levels are normally distributed in the population, with mean $\mu_pi$ and variance $\sigma^2_\pi$ (both of which are unknown). 
The empirical Bayes approach is concerned with estimating $\mu_\pi$ and $\sigma^2_\pi$ from the data using the marginal distribution $m(x)$. 
This follows somewhat closely with the hierarchical model laid out in Gelman et al., (2013), section 5.4 and the eight schools example in section 5.5. 

## 4.6 Hierarchical Bayes 

I skipped this section because I prefer the treatment in Gelman et al., (2013). 

## 4.7 Bayesian Robustness 

This section addresses robustness of Bayesian analysis to prior specification. 
There is a very short discussion of robustness of decision analysis to the choice of loss function at the very end of the section, but the authors argue that the choice of prior is far more challenging with greater implications for resulting decisions. 


